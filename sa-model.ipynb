{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentiment_data():\n",
    "    df = pd.read_excel(\"data/THY_SA_Dataset.xlsx\")\n",
    "    df = df.loc[df[\"Sentiment\"].isin([\"neutral\", \"negative\", \"positive\"])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@TK_HelpDesk Özel mesaj attım size</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>tr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mim, Rezervasyon, TR, Yorum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n                \\n                    Gurbet...</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bilet Fiyati, Kontrol Edildi, mim, Mim Post Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yoğunluk #thy</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>Cagri Merkezi islemleri, mim, Reporting, TR, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daha bir ay önce kırdığınız  valizimin yerine ...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@TK_HelpDesk Çalışma arkadaşlarınız gerekli ha...</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>tr</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content       Date Language  \\\n",
       "0                 @TK_HelpDesk Özel mesaj attım size 2021-05-28       tr   \n",
       "1  \\n                \\n                    Gurbet... 2021-05-26       tr   \n",
       "2                                      Yoğunluk #thy 2021-04-26       tr   \n",
       "3  Daha bir ay önce kırdığınız  valizimin yerine ... 2021-02-01       tr   \n",
       "4  @TK_HelpDesk Çalışma arkadaşlarınız gerekli ha... 2021-02-02       tr   \n",
       "\n",
       "  Sentiment                                               Tags  \n",
       "0   neutral                        mim, Rezervasyon, TR, Yorum  \n",
       "1  negative  Bilet Fiyati, Kontrol Edildi, mim, Mim Post Yo...  \n",
       "2  negative  Cagri Merkezi islemleri, mim, Reporting, TR, Y...  \n",
       "3  negative      Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum  \n",
       "4  positive      Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sr/r72219hj06x_1xvw7hhd517h0000gn/T/ipykernel_37995/1520805587.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.replace(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\", \"\")\n",
      "/var/folders/sr/r72219hj06x_1xvw7hhd517h0000gn/T/ipykernel_37995/1520805587.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.replace(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))#([A-Za-z]+[A-Za-z0-9-_]+)\", \"\")\n",
      "/var/folders/sr/r72219hj06x_1xvw7hhd517h0000gn/T/ipykernel_37995/1520805587.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.replace(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>özel mesaj attım size</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>tr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mim, Rezervasyon, TR, Yorum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gurbetçiler bu sene arabayla gidiyor vatanları...</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>Bilet Fiyati, Kontrol Edildi, mim, Mim Post Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yoğunluk</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>Cagri Merkezi islemleri, mim, Reporting, TR, Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daha bir ay önce kırdığınız  valizimin yerine ...</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>çalışma arkadaşlarınız gerekli hassasiyeti gös...</td>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>tr</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content       Date Language  \\\n",
       "0                              özel mesaj attım size 2021-05-28       tr   \n",
       "1  gurbetçiler bu sene arabayla gidiyor vatanları... 2021-05-26       tr   \n",
       "2                                           yoğunluk 2021-04-26       tr   \n",
       "3  daha bir ay önce kırdığınız  valizimin yerine ... 2021-02-01       tr   \n",
       "4  çalışma arkadaşlarınız gerekli hassasiyeti gös... 2021-02-02       tr   \n",
       "\n",
       "  Sentiment                                               Tags  \n",
       "0   neutral                        mim, Rezervasyon, TR, Yorum  \n",
       "1  negative  Bilet Fiyati, Kontrol Edildi, mim, Mim Post Yo...  \n",
       "2  negative  Cagri Merkezi islemleri, mim, Reporting, TR, Y...  \n",
       "3  negative      Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum  \n",
       "4  positive      Hasarli Bagaj, Kontrol Edildi, mim, TR, Yorum  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiments = read_sentiment_data()\n",
    "display(df_sentiments.head())\n",
    "df_sentiments.drop(columns=[\"Date\", \"Language\", \"Tags\"])\n",
    "df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.replace(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9-_]+)\", \"\")\n",
    "df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.replace(\"(?<=^|(?<=[^a-zA-Z0-9-_\\.]))#([A-Za-z]+[A-Za-z0-9-_]+)\", \"\")\n",
    "df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.replace(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)\", \"\")\n",
    "#df_sentiments[\"Content\"] = df_sentiments['Content'].str.replace(\"[^a-zA-Z#öüçğşıÖÜÇĞŞİ]\", \" \")\n",
    "df_sentiments[\"Content\"] = df_sentiments[\"Content\"].replace(\"\\n\", \"\", regex=True)\n",
    "df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.strip()\n",
    "\n",
    "trans = str.maketrans(\"ÖÜŞÇĞİ\", \"öüşçği\")\n",
    "df_sentiments[\"Content\"] = df_sentiments[\"Content\"].str.translate(trans).str.lower()\n",
    "\n",
    "df_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     845\n",
       "negative    845\n",
       "positive    745\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = df_sentiments.loc[df_sentiments[\"Sentiment\"].isin([\"positive\"])]\n",
    "neg = df_sentiments.loc[df_sentiments[\"Sentiment\"].isin([\"negative\"])]\n",
    "neut = df_sentiments.loc[df_sentiments[\"Sentiment\"].isin([\"neutral\"])]\n",
    "concat = pd.concat([pos.sample(n=745, random_state=54), neg.sample(n=745 + 100, random_state=54), neut.sample(n=745 + 100, random_state=54)]).sample(frac=1, random_state=54)\n",
    "concat[\"Sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>slm ben fransada ikamet ediyorum . ama genevre...</td>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>tr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Belge - PCR - Aşı, cozumlendi, mim, Mim Post Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16093</th>\n",
       "      <td>#türkhavayolları    tk2337 sefer sayılı izmir ...</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>tr</td>\n",
       "      <td>negative</td>\n",
       "      <td>mim, TR, Yorum, Zamaninda Kalkis - Varis (Rotar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22813</th>\n",
       "      <td>allah razi olsun çok taşakkür ederim sağ olun.</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>tr</td>\n",
       "      <td>positive</td>\n",
       "      <td>Evcil Hayvan, Kontrol Edildi, Kontrol Ettim, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14653</th>\n",
       "      <td>yurt disi ucuslar devam edecek mi? bileti olan...</td>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>tr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mim, Mim Post Yorum, Rezervasyon, TR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8213</th>\n",
       "      <td>tesekkur ediyorum..</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>tr</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mim, Rezervasyon, TR, Yorum, Yuksek Takipci</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content       Date Language  \\\n",
       "8131   slm ben fransada ikamet ediyorum . ama genevre... 2021-07-09       tr   \n",
       "16093  #türkhavayolları    tk2337 sefer sayılı izmir ... 2021-03-03       tr   \n",
       "22813     allah razi olsun çok taşakkür ederim sağ olun. 2021-02-23       tr   \n",
       "14653  yurt disi ucuslar devam edecek mi? bileti olan... 2021-04-26       tr   \n",
       "8213                                 tesekkur ediyorum.. 2021-04-27       tr   \n",
       "\n",
       "      Sentiment                                               Tags  \n",
       "8131    neutral  Belge - PCR - Aşı, cozumlendi, mim, Mim Post Y...  \n",
       "16093  negative   mim, TR, Yorum, Zamaninda Kalkis - Varis (Rotar)  \n",
       "22813  positive  Evcil Hayvan, Kontrol Edildi, Kontrol Ettim, m...  \n",
       "14653   neutral               mim, Mim Post Yorum, Rezervasyon, TR  \n",
       "8213    neutral        mim, Rezervasyon, TR, Yorum, Yuksek Takipci  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  1948\n",
      "Test:  374\n"
     ]
    }
   ],
   "source": [
    "training = concat.groupby('Sentiment').apply(lambda x : x.sample(frac = 0.8))\n",
    "test = pd.concat([concat,training]).drop_duplicates(keep=False)\n",
    "\n",
    "print(\"Training: \", len(training))\n",
    "print(\"Test: \", len(test))\n",
    "\n",
    "training_texts = training.Content.values\n",
    "training_labels = training.Sentiment.values\n",
    "\n",
    "test_texts = test.Content.values\n",
    "test_labels = test.Sentiment.values\n",
    "\n",
    "coder = LabelEncoder()\n",
    "coder.fit(training_labels)\n",
    "training_labels = coder.transform(training_labels)\n",
    "test_labels = coder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/berkayg/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  merhaba, kıbrıs dönüş biletim için bir tarife değişikliği olmuştu.bu değişiklik nedeniyle yeni bilet basımı gerçekleşecekti ancak 24 saat geçmesine rağmen tarafıma herhangi bir bilgilendirme maili gelmedi.konu ile ilgili bilgi verilmesini rica ederim.\n",
      "Token IDs: tensor([     2,   5389,     16,   4410,   3312, 110423,   2013,   1947,  18902,\n",
      "          8127,   8326,     18,   1964,   4384,   3426,   2262,   6138,  39688,\n",
      "         11996,   2015,   2591,   3444,   2625,  19641,   3611,  50103,   3485,\n",
      "          1947,  11039,  54295,  13125,     18,   2580,   2037,   2516,   2990,\n",
      "         15766,  10203,   4910,     18,      3,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in training_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 128,      \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(training_labels)\n",
    "\n",
    "print('Original: ', training_texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size \n",
    "        )\n",
    "\n",
    "number_of_categories = len(concat['Sentiment'].unique())\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
    "    num_labels = number_of_categories, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berkayg/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 4\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5,\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Average training loss: 0.00\n",
      "Training epoch took: 0:00:01\n",
      "======== Epoch 2 / 4 ========\n",
      "Average training loss: 0.00\n",
      "Training epoch took: 0:00:01\n",
      "======== Epoch 3 / 4 ========\n",
      "Average training loss: 0.00\n",
      "Training epoch took: 0:00:01\n",
      "======== Epoch 4 / 4 ========\n",
      "Average training loss: 0.00\n",
      "Training epoch took: 0:00:01\n",
      "Training completed in 0:00:05 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "seed_val = 1903\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        output = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels)\n",
    "        loss = output['loss']\n",
    "        logits = output['logits']\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Time': training_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/berkayg/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in test_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 128,          \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',   \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(test_labels)\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started on test data\n",
      "Prediction completed\n"
     ]
    }
   ],
   "source": [
    "print('Prediction started on test data')\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('Prediction completed')\n",
    "\n",
    "prediction_set = []\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  prediction_set.append(pred_labels_i)\n",
    "\n",
    "prediction_scores = [item for sublist in prediction_set for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.902143622743471\n",
      "Recall:  0.9181940221723224\n",
      "Precision:  0.8918728155010349\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       156\n",
      "           1       0.97      0.87      0.92       158\n",
      "           2       0.81      0.94      0.87        49\n",
      "\n",
      "    accuracy                           0.91       363\n",
      "   macro avg       0.89      0.92      0.90       363\n",
      "weighted avg       0.92      0.91      0.91       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
    "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
    "recall = recall_score(test_labels, prediction_scores, average='macro')\n",
    "\n",
    "print(\"F-Score: \", f_score)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)\n",
    "\n",
    "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))\n",
    "# report = report.rename(columns={'0':'dunya',\n",
    "#                           '1':'ekonomi',\n",
    "#                           '2':'kultur',\n",
    "#                           '3':'saglik',\n",
    "#                           '4':'siyaset',\n",
    "#                           '5':'spor',\n",
    "#                           '6':'teknoloji'})\n",
    "\n",
    "print(classification_report(test_labels, prediction_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(coder.classes_, coder.transform(coder.classes_)))\n",
    "le_code_mapping = dict(zip(coder.transform(coder.classes_), coder.classes_))\n",
    "def prediction_pipeline(text):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 128,          \n",
    "                        padding = \"max_length\",\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',   \n",
    "                    )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    with torch.no_grad():\n",
    "        device_input_ids = input_ids.to(device)\n",
    "        device_attention_masks = attention_masks.to(device)\n",
    "        outputs = model(device_input_ids, token_type_ids=None, \n",
    "                        attention_mask=device_attention_masks)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    # logits = logits.detach().cpu().numpy()\n",
    "    probs = F.softmax(logits[0], dim=0)\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    label = np.argmax(probs, axis=0).flatten()\n",
    "    prob = np.max(probs, axis=0).flatten()[0]\n",
    "    prob = round(prob, 5)\n",
    "    print(f\"Text:\\n{text}\\n\\nLabel: {le_code_mapping[label[0]]}\\nProb: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "müşteri hizmetlerine bağlanmak için 28 dakikadır telefonda bekleten firma. aramanın alınma sırasına göre telefonlara cevap verildiğini söylediklerini de dikkate alırsak tüm türkiye ile 5 kişi falan görüşmeye çalışıyor sanırım yoksa mantıklı bir açıklaması yok. 7 gün 24 saat müşteri hizmetleri taahüdünü kesinlikle yerine getirmeyen şirkettir.\n",
      "\n",
      "Label: negative\n",
      "Prob: 0.99\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"müşteri hizmetlerine bağlanmak için 28 dakikadır telefonda bekleten firma. aramanın alınma sırasına göre telefonlara cevap verildiğini söylediklerini de dikkate alırsak tüm türkiye ile 5 kişi falan görüşmeye çalışıyor sanırım yoksa mantıklı bir açıklaması yok. 7 gün 24 saat müşteri hizmetleri taahüdünü kesinlikle yerine getirmeyen şirkettir.\"\"\"\n",
    "prediction_pipeline(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0, 'neutral': 1, 'positive': 2}\n"
     ]
    }
   ],
   "source": [
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model/Turkish-SA.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "deneme_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
    "    num_labels = number_of_categories, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "deneme_model.to(device)\n",
    "for param in deneme_model.parameters():\n",
    "    param.required_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneme_model.load_state_dict(torch.load(\"model/Turkish-SA.pth\"))\n",
    "deneme_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "harika içerik\n",
      "\n",
      "Label: positive\n",
      "Prob: 0.99\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(coder.classes_, coder.transform(coder.classes_)))\n",
    "le_code_mapping = dict(zip(coder.transform(coder.classes_), coder.classes_))\n",
    "def prediction_pipeline(text):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = 128,          \n",
    "                        padding = \"max_length\",\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',   \n",
    "                    )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    with torch.no_grad():\n",
    "        device_input_ids = input_ids.to(device)\n",
    "        device_attention_masks = attention_masks.to(device)\n",
    "        outputs = deneme_model(device_input_ids, token_type_ids=None, \n",
    "                        attention_mask=device_attention_masks)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    # logits = logits.detach().cpu().numpy()\n",
    "    probs = F.softmax(logits[0], dim=0)\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    label = np.argmax(probs, axis=0).flatten()\n",
    "    prob = np.max(probs, axis=0).flatten()[0]\n",
    "    prob = round(prob, 5)\n",
    "    print(f\"Text:\\n{text}\\n\\nLabel: {le_code_mapping[label[0]]}\\nProb: {prob:.2f}\")\n",
    "prediction_pipeline(\"harika içerik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"model/Turkish-SA-model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'neutral', 2: 'positive'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_code_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41d713f275066d064510f21e3d53f42d29ca2528eb946dd8ffa19abe6e903070"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
